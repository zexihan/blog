---
layout:     post
title:      "<>DS - Big(O)"
subtitle:   "DS Note"
date:       2016-11-14
author:     "Zexi"
header-img: "img/post-bg-js-module.jpg"
catalog: true
tags:
    - Algorithms
    - Data Structure
---



## Big(O)

一种数据结构所支持的操作，有其时间上的“代价”，我们用时间复杂度这个概念来衡量。时间复杂度，是指算法运行时间与输入数据量的函数关系，常用大写字母O表示。时间复杂度是渐进的：当输入数据量逐渐增加以至趋于无穷时，算法运行时间渐近于某个关于数据量n的函数。

时间复杂度不仅有Big O一种表述方式，而且Big O的数学含义较为复杂，可以参考《算法导论》等材料查看细节。我们学习数据结构时，只需要知道Big O表示输入量和操作运行时间的关系。而且，我们只取变化量最大的关系(比如多项式中最高次数的项)，而且所有的系数都是1。

比如，如果一个操作对任何大小为n的输入，最多需要2n^2 + 3n时间运行，这个操作的时间复杂度仍然是O(n^2)，因为n趋于无穷时，系数和n项相比之下就没有那么“重要”。这一性质，是Big O的渐进性质造成的。【准确？】

有些操作在不同情况下时间复杂度也是不一样的，通常分为平均情况和最坏情况两种，我们通常使用最坏情况来衡量，有时也使用平均情况。本笔记除非特别说明，所指都是最坏情况。

现在，我们来看几种常见的时间复杂度，及其常见的例子。

* O(1) 

这是最理想的时间复杂度，它说明操作的运行时间是恒定的，不受输入的数据所影响。 其实，O(1)的算法也许花费了很长的绝对时间。但它不受输入数据的大小影响，所以输入的数据很大的时候，O(1)算法就会显得越来越“省力“。这里需要再次强调，Big O是输入量和运行时间相对的关系，而不是绝对的运行时间。

* O(log n) 

说明输入数据和运行时间是log n的关系，运行时间比数据的增长慢一些。一个典型的O(log n)算法是Binary Search算法，我们后面会讲。

* O(n) 

说明运行时间和输入数据的增长速度是一致的，又称为线性(linear)时间。常见于循环中，Linear Search也是O(n)的。

* O(n log n) 

通常，这一复杂度的出现说明O(n)的操作被执行了log n次，或者O(log n)操作被执行了n次。常见于QuickSort和MergeSort等排序算法，是排序算法的一种理想的复杂度。

* O(n^2^) 

又称为二次(Quadratic)时间，运行时间增长速度是输入数据增长速度的平方。比如，输入了3倍的数据，则运行时间是以前的9倍。常见情况下，这就是一种比较差的复杂度了。常见于嵌套for loop，比如BubbleSort。

* O(2^n^) 

指数复杂度，运行时间是2的n次方倍，效率极低，应当避免。斐波那契数列按照定义可以用指数复杂度的递归算法实现： 

```java
public int Fibonacci(n) { 
    if (n == 1 || n == 2) return 1; 
    if (n > 2) return Fibonacci(n-1) + Fibonacci(n-2); 
}
```

为什么是2^n^呢？因为每一次呼叫递归函数，都会打开新的一层栈桢(stack frame)，形成一个层数为n - 1的二叉树，从每一层有2^0^项，延展到每一层有2^n-1^项，2^0^ + ... + 2^n-1^是2^n^-1。注意这个二叉树不是完全的，2^n^只是趋近值。

* O(n!) 阶乘复杂度，注意它比指数复杂度更慢，是应当绝对避免的。 *Permutation
